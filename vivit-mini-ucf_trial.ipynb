{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["hi\n"]}],"source":["print(\"hi\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:25:34.347538Z","iopub.status.busy":"2022-12-30T14:25:34.347046Z","iopub.status.idle":"2022-12-30T14:25:40.603017Z","shell.execute_reply":"2022-12-30T14:25:40.601868Z","shell.execute_reply.started":"2022-12-30T14:25:34.347442Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import ipywidgets"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:08:21.337991Z","iopub.status.busy":"2022-12-30T14:08:21.337244Z","iopub.status.idle":"2022-12-30T14:08:21.354381Z","shell.execute_reply":"2022-12-30T14:08:21.353001Z","shell.execute_reply.started":"2022-12-30T14:08:21.337949Z"},"id":"itk9H3ytMIq3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  0\n","2.10.0\n"]},{"data":{"text/plain":["'3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","tf.test.is_built_with_cuda()\n","print(tf.version.VERSION)\n","import sys\n","sys.version"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:15:42.127108Z","iopub.status.busy":"2022-12-30T14:15:42.126682Z","iopub.status.idle":"2022-12-30T14:15:52.144490Z","shell.execute_reply":"2022-12-30T14:15:52.143617Z","shell.execute_reply.started":"2022-12-30T14:15:42.127072Z"},"trusted":true},"outputs":[],"source":["# ! pip install opencv-python"]},{"cell_type":"markdown","metadata":{"id":"3IQLjkXIMIq4"},"source":["## Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:25:40.605904Z","iopub.status.busy":"2022-12-30T14:25:40.605115Z","iopub.status.idle":"2022-12-30T14:25:41.379407Z","shell.execute_reply":"2022-12-30T14:25:41.377784Z","shell.execute_reply.started":"2022-12-30T14:25:40.605859Z"},"id":"LhaEi9ToMIq5","trusted":true},"outputs":[],"source":["import os\n","import io\n","import matplotlib.pyplot as plt\n","import cv2\n","import imageio\n","#import medmnist\n","#import ipywidgets\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import cv2 as cv\n","\n","# Setting seed for reproducibility\n","SEED = 42\n","os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n","np.random.seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"WhnaMHXmMIq6"},"source":["## Hyperparameters\n","\n","The hyperparameters are chosen via hyperparameter\n","search. You can learn more about the process in the \"conclusion\" section."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:25:44.094568Z","iopub.status.busy":"2022-12-30T14:25:44.094020Z","iopub.status.idle":"2022-12-30T14:25:44.101903Z","shell.execute_reply":"2022-12-30T14:25:44.101032Z","shell.execute_reply.started":"2022-12-30T14:25:44.094516Z"},"id":"ebygdrVVMIq7","trusted":true},"outputs":[],"source":["# DATA\n","DATASET_NAME = \"UCF-Crime-mini\"\n","BATCH_SIZE = 128\n","#AUTO = tf.data.AUTOTUNE\n","INPUT_SHAPE = (15, 100, 100, 1)\n","NUM_CLASSES = 13\n","TRAIN_RATIO = 0.7\n","TEST_RATIO = 0.25\n","VALIDATION_RATIO = 0.05\n","\n","# OPTIMIZER\n","LEARNING_RATE = 1e-4\n","WEIGHT_DECAY = 1e-5\n","\n","# TRAINING\n","EPOCHS = 60\n","\n","# TUBELET EMBEDDING\n","PATCH_SIZE = (8, 8, 8)\n","NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n","\n","# ViViT ARCHITECTURE\n","LAYER_NORM_EPS = 1e-6\n","PROJECTION_DIM = 128\n","NUM_HEADS = 8\n","NUM_LAYERS = 8"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:25:54.726291Z","iopub.status.busy":"2022-12-30T14:25:54.725830Z","iopub.status.idle":"2022-12-30T14:25:54.732505Z","shell.execute_reply":"2022-12-30T14:25:54.731539Z","shell.execute_reply.started":"2022-12-30T14:25:54.726255Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'ROOT_PATH = \"../datasets/ucf-crime-mini/dataset\"\\n\\nAbuse_PATH = ROOT_PATH + \\'/Abuse\\'\\nArrest_PATH = ROOT_PATH + \\'/Arrest\\'\\nAssault_PATH = ROOT_PATH + \\'/Assault\\'\\nBurglary_PATH = ROOT_PATH + \\'/Burglary\\'\\nFighting_PATH = ROOT_PATH + \\'/Fighting\\'\\nNormal_PATH = ROOT_PATH + \\'/normal\\'\\n\\n\\n\\nOUT_PATH = \"../out/vivit-ucf-mini/\"'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["'''ROOT_PATH = \"../datasets/ucf-crime-mini/dataset\"\n","\n","Abuse_PATH = ROOT_PATH + '/Abuse'\n","Arrest_PATH = ROOT_PATH + '/Arrest'\n","Assault_PATH = ROOT_PATH + '/Assault'\n","Burglary_PATH = ROOT_PATH + '/Burglary'\n","Fighting_PATH = ROOT_PATH + '/Fighting'\n","Normal_PATH = ROOT_PATH + '/normal'\n","\n","\n","\n","OUT_PATH = \"../out/vivit-ucf-mini/\"'''"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:26:05.062889Z","iopub.status.busy":"2022-12-30T14:26:05.062472Z","iopub.status.idle":"2022-12-30T14:26:05.075388Z","shell.execute_reply":"2022-12-30T14:26:05.073199Z","shell.execute_reply.started":"2022-12-30T14:26:05.062854Z"},"trusted":true},"outputs":[],"source":["def extract_frames(directory, dimensions=(INPUT_SHAPE[1], INPUT_SHAPE[2]), packet_length = INPUT_SHAPE[0], save_dir_path = None):\n","    data = []\n","\n","    for video_name in os.listdir(directory):\n","        video = cv2.VideoCapture(directory + '/' + video_name)\n","        packet = []\n","        while video.isOpened():\n","            ret, frame = video.read()\n","\n","            if not ret: # no more frames\n","                break\n","\n","            del ret\n","\n","            # capturing the frame\n","\n","            frame = cv2.resize(frame, dimensions, interpolation = cv2.INTER_AREA)\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            packet.append(frame)\n","            del frame\n","\n","            if len(packet) == packet_length: \n","                '''\n","                consecutive packets share 14 of the 15 frames to generate more data\n","                '''\n","                # packet itself is not normalized\n","                stacked = np.array(packet) # convert to numpy and normalize packet\n","                data.append(stacked.copy()) # this .copy() is not in the original code \n","                del packet\n","                packet = []\n","\n","\n","        video.release()\n","        cv2.destroyAllWindows()\n","\n","    del packet\n","    # TODO: read the docs for the next 2 lines\n","    data = np.stack(data, axis= 0)\n","#     data = np.moveaxis(data, 1 ,-1)\n","\n","    # save to disk\n","    if(save_dir_path is not None):\n","        np.save(f'{save_dir_path}/data', data)\n","\n","    return data"]},{"cell_type":"markdown","metadata":{},"source":["## Extracting frames for 14 class"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##Testing on UCF"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["Abuse_frames_ucf = np.load(r\"G:\\UCF-crime\\Abuse_frames.npy\")\n","Arrest_frames_ucf = np.load(r\"G:\\UCF-crime\\Arrest_frames.npy\")\n","Assault_frames_ucf = np.load(r\"G:\\UCF-crime\\Assault_frames.npy\")\n","Burglary_frames_ucf = np.load(r\"G:\\UCF-crime\\Burglary_frames.npy\")\n","Fighting_frames_ucf = np.load(r\"G:\\UCF-crime\\Fighting_frames.npy\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:21:30.553160Z","iopub.status.busy":"2022-12-30T14:21:30.552713Z","iopub.status.idle":"2022-12-30T14:21:30.560388Z","shell.execute_reply":"2022-12-30T14:21:30.559137Z","shell.execute_reply.started":"2022-12-30T14:21:30.553125Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(38331, 15, 100, 100)\n"]}],"source":["print(Abuse_frames_ucf.shape)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["abuse_test =Abuse_frames_ucf[:1000]\n","arrest_test = Arrest_frames_ucf[:1000]\n","assault_test = Assault_frames_ucf[:1000]\n","burglary_test = Burglary_frames_ucf[:1000]\n","fighting_test = Fighting_frames_ucf[:1000]\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["test_data = np.concatenate((abuse_test, arrest_test, assault_test, burglary_test, fighting_test), axis=0)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:27:26.960263Z","iopub.status.busy":"2022-12-30T14:27:26.959824Z","iopub.status.idle":"2022-12-30T14:27:26.967299Z","shell.execute_reply":"2022-12-30T14:27:26.965652Z","shell.execute_reply.started":"2022-12-30T14:27:26.960230Z"},"trusted":true},"outputs":[],"source":["abuse_labels = np.full((abuse_test.shape[0]), 0)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:29:51.785264Z","iopub.status.busy":"2022-12-30T14:29:51.784806Z","iopub.status.idle":"2022-12-30T14:29:51.791961Z","shell.execute_reply":"2022-12-30T14:29:51.790013Z","shell.execute_reply.started":"2022-12-30T14:29:51.785226Z"},"trusted":true},"outputs":[],"source":["arrest_labels = np.full((arrest_test.shape[0]), 1)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:22:18.194565Z","iopub.status.busy":"2022-12-30T14:22:18.194069Z","iopub.status.idle":"2022-12-30T14:22:18.202156Z","shell.execute_reply":"2022-12-30T14:22:18.200411Z","shell.execute_reply.started":"2022-12-30T14:22:18.194524Z"},"trusted":true},"outputs":[],"source":["assault_labels = np.full((assault_test.shape[0]), 2)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:22:28.135719Z","iopub.status.busy":"2022-12-30T14:22:28.134934Z","iopub.status.idle":"2022-12-30T14:22:28.141767Z","shell.execute_reply":"2022-12-30T14:22:28.140899Z","shell.execute_reply.started":"2022-12-30T14:22:28.135637Z"},"trusted":true},"outputs":[],"source":["burglary_labels = np.full((burglary_test.shape[0]), 3)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T14:22:46.156491Z","iopub.status.busy":"2022-12-30T14:22:46.156083Z","iopub.status.idle":"2022-12-30T14:22:46.164110Z","shell.execute_reply":"2022-12-30T14:22:46.161973Z","shell.execute_reply.started":"2022-12-30T14:22:46.156458Z"},"trusted":true},"outputs":[],"source":["fighting_labels = np.full((fighting_test.shape[0]), 4)"]},{"cell_type":"markdown","metadata":{},"source":["# Loading frames"]},{"cell_type":"markdown","metadata":{},"source":["# Data split"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 2 3 4]\n"]}],"source":["y = np.concatenate((abuse_labels, arrest_labels, assault_labels, burglary_labels, fighting_labels))\n","print(np.unique(y))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(5000, 15, 100, 100)\n","(5000,)\n"]}],"source":["print(test_data.shape)\n","print(y.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import gc\n","for i in range(100):\n","    gc.collect()"]},{"cell_type":"code","execution_count":20,"metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":["'from sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(\\n x, y, test_size=0.3, random_state=42, stratify = y)\\n\\nX_test, X_validate, y_test, y_validate = train_test_split(\\n X_test, y_test, test_size=0.2, random_state=42, stratify = y_test)'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["'''from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n"," x, y, test_size=0.3, random_state=42, stratify = y)\n","\n","X_test, X_validate, y_test, y_validate = train_test_split(\n"," X_test, y_test, test_size=0.2, random_state=42, stratify = y_test)'''"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["#print( X_train.shape, X_test.shape, X_validate.shape, y_train.shape, y_test.shape, y_validate.shape)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#print(y_train[3], X_train.shape)\n","#plt.imshow(X_train[3][0])\n","#plt.axis('off')"]},{"cell_type":"markdown","metadata":{"id":"P_XGA2IZMIq-"},"source":["### `tf.data` pipeline"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["tf.config.list_physical_devices('CPU')"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'X_train' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[26], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m             y[i,] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_grayscale_image(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask_path \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[ID])\n\u001b[0;32m     80\u001b[0m         \u001b[39mreturn\u001b[39;00m y\n\u001b[1;32m---> 81\u001b[0m training_generator \u001b[39m=\u001b[39m DataGenerator(X_train, y_train)\n\u001b[0;32m     82\u001b[0m validation_generator \u001b[39m=\u001b[39m DataGenerator(X_validate, y_validate)\n","\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"]}],"source":["import numpy as np\n","import cv2\n","from tensorflow.keras.utils import Sequence\n","\n","\n","class DataGenerator(Sequence):\n","    def __init__(self, list_IDs, labels,\n","                 to_fit=True, batch_size=128, dim=(15, 100, 100),\n","                 n_channels=1, n_classes=13, shuffle=True):\n","        self.list_IDs = list_IDs\n","        self.labels = labels\n","        self.to_fit = to_fit\n","        self.batch_size = batch_size\n","        self.dim = dim\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\n","        :return: number of batches per epoch\n","        \"\"\"\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        \"\"\"Generate one batch of data\n","        :param index: index of the batch\n","        :return: X and y when fitting. X only when predicting\n","        \"\"\"\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X = self._generate_X(list_IDs_temp)\n","\n","        if self.to_fit:\n","            y = self._generate_y(list_IDs_temp)\n","            return X, y\n","        else:\n","            return X\n","\n","    def on_epoch_end(self):\n","        \"\"\"Updates indexes after each epoch\n","        \"\"\"\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def _generate_X(self, list_IDs_temp):\n","        \"\"\"Generates data containing batch_size images\n","        :param list_IDs_temp: list of label ids to load\n","        :return: batch of images\n","        \"\"\"\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            X[i,] = self._load_grayscale_image(self.image_path + self.labels[ID])\n","\n","        return X\n","\n","    def _generate_y(self, list_IDs_temp):\n","        \"\"\"Generates data containing batch_size masks\n","        :param list_IDs_temp: list of label ids to load\n","        :return: batch if masks\n","        \"\"\"\n","        y = np.empty((self.batch_size, *self.dim), dtype=int)\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            y[i,] = self._load_grayscale_image(self.mask_path + self.labels[ID])\n","\n","        return y\n","training_generator = DataGenerator(X_train, y_train)\n","validation_generator = DataGenerator(X_validate, y_validate)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["52"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["len(training_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["((574, 15, 100, 100), (6687,))"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["X_validate.shape, y_train.shape"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"igqdpz27MIq_"},"outputs":[],"source":["\n","class TubeletEmbedding(layers.Layer):\n","    def __init__(self, embed_dim, patch_size, **kwargs):\n","        super().__init__(**kwargs)\n","        self.projection = layers.Conv3D(\n","            filters=embed_dim,\n","            kernel_size=patch_size,\n","            strides=patch_size,\n","            padding=\"VALID\",\n","        )\n","        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n","\n","    def call(self, videos):\n","        projected_patches = self.projection(videos)\n","        flattened_patches = self.flatten(projected_patches)\n","        return flattened_patches\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"9P4kswaIMIrA"},"outputs":[],"source":["\n","class PositionalEncoder(layers.Layer):\n","    def __init__(self, embed_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","\n","    def build(self, input_shape):\n","        _, num_tokens, _ = input_shape\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_tokens, output_dim=self.embed_dim\n","        )\n","        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n","\n","    def call(self, encoded_tokens):\n","        # Encode the positions and add it to the encoded tokens\n","        encoded_positions = self.position_embedding(self.positions)\n","        encoded_tokens = encoded_tokens + encoded_positions\n","        return encoded_tokens\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"tIWQUMvdMIrB"},"outputs":[],"source":["\n","def create_vivit_classifier(\n","    tubelet_embedder,\n","    positional_encoder,\n","    input_shape=INPUT_SHAPE,\n","    transformer_layers=NUM_LAYERS,\n","    num_heads=NUM_HEADS,\n","    embed_dim=PROJECTION_DIM,\n","    layer_norm_eps=LAYER_NORM_EPS,\n","    num_classes=NUM_CLASSES,\n","):\n","    # Get the input layer\n","    inputs = layers.Input(shape=input_shape)\n","    # Create patches.\n","    patches = tubelet_embedder(inputs)\n","    # Encode patches.\n","    encoded_patches = positional_encoder(patches)\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(transformer_layers):\n","        # Layer normalization and MHSA\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n","        )(x1, x1)\n","\n","        # Skip connection\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","\n","        # Layer Normalization and MLP\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        x3 = keras.Sequential(\n","            [\n","                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n","                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n","            ]\n","        )(x3)\n","\n","        # Skip connection\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Layer normalization and Global average pooling.\n","    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n","    representation = layers.GlobalAvgPool1D()(representation)\n","\n","    # Classify outputs.\n","    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n","\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["model_checkpoint = ModelCheckpoint('C:/Users/MOhanad/Downloads/checkpoints/vivit-mini-ucf',\n","                monitor='val_loss',\n","                save_best_only=True)"]},{"cell_type":"markdown","metadata":{"id":"qmGYIJZaMIrC"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L2mQonRkMIrC"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","Epoch 1/60\n"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:07:05.124449: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"_cardinality\"\n","  value {\n","    i: -2\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_7398\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"metadata\"\n","  value {\n","    s: \"\\n\\021FlatMapDataset:26\"\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n","experimental_type {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_DATASET\n","    args {\n","      type_id: TFT_PRODUCT\n","      args {\n","        type_id: TFT_TENSOR\n","        args {\n","          type_id: TFT_INT64\n","        }\n","      }\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2022-12-30 15:07:05.181563: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - ETA: 0s - loss: 1.4186 - accuracy: 0.4483 - top-5-accuracy: 0.9595"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:10:26.833388: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"_cardinality\"\n","  value {\n","    i: -2\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_19676\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"metadata\"\n","  value {\n","    s: \"\\n\\021FlatMapDataset:54\"\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n","experimental_type {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_DATASET\n","    args {\n","      type_id: TFT_PRODUCT\n","      args {\n","        type_id: TFT_TENSOR\n","        args {\n","          type_id: TFT_INT64\n","        }\n","      }\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2022-12-30 15:10:26.887364: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 222s 1s/step - loss: 1.4186 - accuracy: 0.4483 - top-5-accuracy: 0.9595 - val_loss: 1.2518 - val_accuracy: 0.5139 - val_top-5-accuracy: 0.9826\n","Epoch 2/60\n","209/209 [==============================] - ETA: 0s - loss: 1.2416 - accuracy: 0.5188 - top-5-accuracy: 0.9713"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:13:59.200602: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 210s 1s/step - loss: 1.2416 - accuracy: 0.5188 - top-5-accuracy: 0.9713 - val_loss: 1.1179 - val_accuracy: 0.5801 - val_top-5-accuracy: 0.9774\n","Epoch 3/60\n","209/209 [==============================] - ETA: 0s - loss: 1.1501 - accuracy: 0.5638 - top-5-accuracy: 0.9770"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:17:27.824616: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 209s 999ms/step - loss: 1.1501 - accuracy: 0.5638 - top-5-accuracy: 0.9770 - val_loss: 1.0583 - val_accuracy: 0.6341 - val_top-5-accuracy: 0.9756\n","Epoch 4/60\n","209/209 [==============================] - ETA: 0s - loss: 1.0411 - accuracy: 0.6226 - top-5-accuracy: 0.9834"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:20:54.896076: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 207s 990ms/step - loss: 1.0411 - accuracy: 0.6226 - top-5-accuracy: 0.9834 - val_loss: 0.9122 - val_accuracy: 0.6289 - val_top-5-accuracy: 0.9878\n","Epoch 5/60\n","209/209 [==============================] - ETA: 0s - loss: 0.8877 - accuracy: 0.6818 - top-5-accuracy: 0.9873"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:24:22.095532: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 208s 993ms/step - loss: 0.8877 - accuracy: 0.6818 - top-5-accuracy: 0.9873 - val_loss: 0.7168 - val_accuracy: 0.7352 - val_top-5-accuracy: 0.9878\n","Epoch 6/60\n","209/209 [==============================] - ETA: 0s - loss: 0.6726 - accuracy: 0.7844 - top-5-accuracy: 0.9891"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:27:50.125812: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 208s 995ms/step - loss: 0.6726 - accuracy: 0.7844 - top-5-accuracy: 0.9891 - val_loss: 0.4749 - val_accuracy: 0.8815 - val_top-5-accuracy: 0.9930\n","Epoch 7/60\n","209/209 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.8469 - top-5-accuracy: 0.9913"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:31:16.928100: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 207s 991ms/step - loss: 0.5149 - accuracy: 0.8469 - top-5-accuracy: 0.9913 - val_loss: 0.3854 - val_accuracy: 0.8937 - val_top-5-accuracy: 1.0000\n","Epoch 8/60\n","209/209 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.9000 - top-5-accuracy: 0.9967"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:34:42.177419: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 205s 981ms/step - loss: 0.3697 - accuracy: 0.9000 - top-5-accuracy: 0.9967 - val_loss: 0.3021 - val_accuracy: 0.9164 - val_top-5-accuracy: 1.0000\n","Epoch 9/60\n","209/209 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.9351 - top-5-accuracy: 0.9982"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:38:07.977216: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 206s 985ms/step - loss: 0.2392 - accuracy: 0.9351 - top-5-accuracy: 0.9982 - val_loss: 0.1967 - val_accuracy: 0.9286 - val_top-5-accuracy: 0.9983\n","Epoch 10/60\n","209/209 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9511 - top-5-accuracy: 0.9996"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:41:33.009151: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 205s 980ms/step - loss: 0.1721 - accuracy: 0.9511 - top-5-accuracy: 0.9996 - val_loss: 0.1390 - val_accuracy: 0.9686 - val_top-5-accuracy: 0.9965\n","Epoch 11/60\n","209/209 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9711 - top-5-accuracy: 0.9991"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:44:56.594950: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 204s 975ms/step - loss: 0.1174 - accuracy: 0.9711 - top-5-accuracy: 0.9991 - val_loss: 0.0646 - val_accuracy: 0.9826 - val_top-5-accuracy: 1.0000\n","Epoch 12/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9804 - top-5-accuracy: 0.9996"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:48:20.540397: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 204s 977ms/step - loss: 0.0792 - accuracy: 0.9804 - top-5-accuracy: 0.9996 - val_loss: 0.0502 - val_accuracy: 0.9878 - val_top-5-accuracy: 1.0000\n","Epoch 13/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9858 - top-5-accuracy: 0.9999"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:51:44.232095: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 914ms/step - loss: 0.0506 - accuracy: 0.9858 - top-5-accuracy: 0.9999 - val_loss: 0.0572 - val_accuracy: 0.9895 - val_top-5-accuracy: 1.0000\n","Epoch 14/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9901 - top-5-accuracy: 0.9997"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:54:55.251898: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 203s 973ms/step - loss: 0.0425 - accuracy: 0.9901 - top-5-accuracy: 0.9997 - val_loss: 0.0287 - val_accuracy: 0.9878 - val_top-5-accuracy: 1.0000\n","Epoch 15/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9942 - top-5-accuracy: 1.0000"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 15:58:18.552181: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 914ms/step - loss: 0.0243 - accuracy: 0.9942 - top-5-accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9826 - val_top-5-accuracy: 1.0000\n","Epoch 16/60\n","209/209 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.9139 - top-5-accuracy: 0.9966"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:01:29.053444: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 912ms/step - loss: 0.2767 - accuracy: 0.9139 - top-5-accuracy: 0.9966 - val_loss: 0.1155 - val_accuracy: 0.9617 - val_top-5-accuracy: 1.0000\n","Epoch 17/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9928 - top-5-accuracy: 0.9999"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:04:39.754753: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 912ms/step - loss: 0.0349 - accuracy: 0.9928 - top-5-accuracy: 0.9999 - val_loss: 0.0370 - val_accuracy: 0.9861 - val_top-5-accuracy: 1.0000\n","Epoch 18/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9951 - top-5-accuracy: 0.9999"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:07:50.722436: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 914ms/step - loss: 0.0224 - accuracy: 0.9951 - top-5-accuracy: 0.9999 - val_loss: 0.0326 - val_accuracy: 0.9913 - val_top-5-accuracy: 1.0000\n","Epoch 19/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9952 - top-5-accuracy: 0.9999"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:11:03.647046: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 206s 985ms/step - loss: 0.0200 - accuracy: 0.9952 - top-5-accuracy: 0.9999 - val_loss: 0.0135 - val_accuracy: 0.9948 - val_top-5-accuracy: 1.0000\n","Epoch 20/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9922 - top-5-accuracy: 0.9999"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:14:30.636785: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 194s 929ms/step - loss: 0.0284 - accuracy: 0.9922 - top-5-accuracy: 0.9999 - val_loss: 0.0257 - val_accuracy: 0.9895 - val_top-5-accuracy: 1.0000\n","Epoch 21/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9969 - top-5-accuracy: 1.0000"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:17:44.511269: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 206s 986ms/step - loss: 0.0120 - accuracy: 0.9969 - top-5-accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9965 - val_top-5-accuracy: 1.0000\n","Epoch 22/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9973 - top-5-accuracy: 1.0000"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:21:07.505519: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 913ms/step - loss: 0.0109 - accuracy: 0.9973 - top-5-accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9930 - val_top-5-accuracy: 1.0000\n","Epoch 23/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9940 - top-5-accuracy: 1.0000"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:24:18.743369: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 204s 975ms/step - loss: 0.0244 - accuracy: 0.9940 - top-5-accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9948 - val_top-5-accuracy: 1.0000\n","Epoch 24/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9945 - top-5-accuracy: 1.0000"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:27:41.681518: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 912ms/step - loss: 0.0184 - accuracy: 0.9945 - top-5-accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9948 - val_top-5-accuracy: 1.0000\n","Epoch 25/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9933 - top-5-accuracy: 0.9997"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:30:52.262250: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 191s 912ms/step - loss: 0.0256 - accuracy: 0.9933 - top-5-accuracy: 0.9997 - val_loss: 0.0753 - val_accuracy: 0.9878 - val_top-5-accuracy: 1.0000\n","Epoch 26/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9885 - top-5-accuracy: 0.9999"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:34:02.626222: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 190s 911ms/step - loss: 0.0423 - accuracy: 0.9885 - top-5-accuracy: 0.9999 - val_loss: 0.1123 - val_accuracy: 0.9652 - val_top-5-accuracy: 1.0000\n","Epoch 27/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9931 - top-5-accuracy: 0.9997"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:37:13.261224: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 203s 971ms/step - loss: 0.0251 - accuracy: 0.9931 - top-5-accuracy: 0.9997 - val_loss: 0.0099 - val_accuracy: 0.9965 - val_top-5-accuracy: 1.0000\n","Epoch 28/60\n","209/209 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9988 - top-5-accuracy: 1.0000"]},{"name":"stderr","output_type":"stream","text":["2022-12-30 16:40:37.747964: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n","WARNING:absl:Found untraced functions such as conv3d_1_layer_call_fn, conv3d_1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, reshape_1_layer_call_fn, reshape_1_layer_call_and_return_conditional_losses while saving (showing 5 of 103). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../checkpoints/vivit-mini-ucf/assets\n"]},{"name":"stdout","output_type":"stream","text":["209/209 [==============================] - 205s 983ms/step - loss: 0.0058 - accuracy: 0.9988 - top-5-accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000 - val_top-5-accuracy: 1.0000\n","Epoch 29/60\n"," 95/209 [============>.................] - ETA: 1:44 - loss: 0.0054 - accuracy: 0.9980 - top-5-accuracy: 1.0000"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/azureuser/workspace/code/vivit-mini-ucf.ipynb Cell 64\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m# _, accuracy, top_5_accuracy = model.evaluate(testloader)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39m# print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39m# print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m model, history \u001b[39m=\u001b[39m run_experiment()\n","\u001b[1;32m/home/azureuser/workspace/code/vivit-mini-ucf.ipynb Cell 64\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         ],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# Train the model.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,y_train, epochs\u001b[39m=\u001b[39;49mEPOCHS, validation_data\u001b[39m=\u001b[39;49m(X_validate,y_validate), callbacks\u001b[39m=\u001b[39;49m[model_checkpoint])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# _, accuracy, top_5_accuracy = model.evaluate(testloader)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2247726164417a757265227d/home/azureuser/workspace/code/vivit-mini-ucf.ipynb#Y116sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","'''def run_experiment():\n","    mirrored_strategy = tf.distribute.MirroredStrategy(devices= [\"/cpu:0\"],cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n","    with mirrored_strategy.scope():\n","    # Initialize model\n","        model = create_vivit_classifier(\n","            tubelet_embedder=TubeletEmbedding(\n","                embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n","            ),\n","            positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n","        )\n","\n","        # Compile the model with the optimizer, loss function\n","        # and the metrics.\n","        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","        model.compile(\n","            optimizer=optimizer,\n","            loss=\"sparse_categorical_crossentropy\",\n","            metrics=[\n","                keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","                keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","            ],\n","        )\n","\n","        # Train the model.\n","        history = model.fit(X_train,y_train, epochs=EPOCHS, validation_data=(X_validate,y_validate), callbacks=[model_checkpoint])\n","\n","        # _, accuracy, top_5_accuracy = model.evaluate(testloader)\n","        # print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","        # print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","\n","    return model, history\n","\n","\n","model, history = run_experiment()'''"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1bf371e0b20>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["model = create_vivit_classifier(\n","    tubelet_embedder=TubeletEmbedding(\n","        embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n","    ),\n","    positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",")\n","\n","# Compile the model with the optimizer, loss function\n","# and the metrics.\n","optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","model.compile(\n","    optimizer=optimizer,\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\n","        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","        keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","    ],\n",")\n","\n","model.load_weights(\"C:/Users/MOhanad/Downloads/checkpoints/vivit-mini-ucf\")"]},{"cell_type":"markdown","metadata":{"id":"oFGwukzfMIrD"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\MOhanad\\AppData\\Local\\Temp\\1\\ipykernel_8040\\3326022288.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.test.is_gpu_available()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["157/157 [==============================] - 53s 322ms/step - loss: 5.4344 - accuracy: 0.1072 - top-5-accuracy: 0.8326\n"]},{"data":{"text/plain":["[5.434434413909912, 0.10719999670982361, 0.8325999975204468]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(test_data,y)\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["157/157 [==============================] - 56s 355ms/step\n","              precision    recall  f1-score   support\n","\n","      normal       0.06      0.04      0.05      1000\n","       abuse       0.19      0.17      0.18      1000\n","      arrest       0.11      0.17      0.13      1000\n","     assault       0.96      0.16      0.28      1000\n","    burglary       0.00      0.00      0.00      1000\n","    fighting       0.00      0.00      0.00         0\n","\n","    accuracy                           0.11      5000\n","   macro avg       0.22      0.09      0.11      5000\n","weighted avg       0.27      0.11      0.13      5000\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\MOhanad\\anazonda\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\MOhanad\\anazonda\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\MOhanad\\anazonda\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["from sklearn.metrics import f1_score, classification_report\n","\n","y_pred = np.argmax(model.predict(test_data),axis=-1)\n","f1_score(y, y_pred, average='micro')\n","\n","target_names = [\n","    \"normal\",\n","    \"abuse\",\n","    \"arrest\",\n","    \"assault\",\n","    \"burglary\",\n","    \"fighting\",\n","]\n","\n","\n","print(classification_report(y, y_pred, target_names=target_names))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["#np.save(\"../out/vivit-ucf-mini/y_train\",y_train)\n","#np.save(\"../out/vivit-ucf-mini/y_test\",y_test)\n","#np.save(\"../out/vivit-ucf-mini/y_validate\",y_validate)\n","np.save(\"G:/UCF-crime/y_pred\",y_pred)\n","\n","#np.save(\"../out/vivit-ucf-mini/X_train\",X_train)\n","np.save(\"G:/UCF-crime/test_data\",test_data)\n","np.save(\"G:/UCF-crime/y\",y)\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["<AxesSubplot: >"]},"execution_count":31,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import seaborn as sns\n","import numpy as np\n","from sklearn.metrics import confusion_matrix as cm\n","\n","y_pred = np.load(\"G:/UCF-crime/y_pred.npy\")\n","y = np.load(\"G:/UCF-crime/y.npy\")\n","conf = cm(y,y_pred)\n","\n","sns.heatmap(conf,annot=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"vivit","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"aaa_kernel","language":"python","name":"aaa_kernel"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"128ebca4d0dad7d8f1dbd74ec0d995d4068860a0fa3125bc12bf13d2b7cc57aa"}}},"nbformat":4,"nbformat_minor":4}
